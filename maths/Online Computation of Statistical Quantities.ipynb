{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "60aba3fc-4876-41a1-9341-0dce8e25ecdc",
   "metadata": {},
   "source": [
    "# Online Computation of Statistical Quantities\n",
    "\n",
    "In many real-world scenarios, datasets can be exceedingly large, making it impractical or even impossible to load the entire dataset into memory at once. However, there are numerous situations where it's crucial to compute statistical quantities such as mean, sum, variance, and covariance from the dataset. This is particularly common in fields like machine learning, signal processing, and data analysis.\n",
    "\n",
    "To address this challenge, we introduce a set of Python classes that implement online computation algorithms for various statistical quantities. Online computation, also known as incremental computation, allows us to calculate statistical measures efficiently by processing data in small batches or one data point at a time, without needing to store the entire dataset in memory simultaneously.\n",
    "\n",
    "The classes provided in this notebook include:\n",
    "\n",
    "- **IterMean**: Computes the mean of the dataset incrementally.\n",
    "- **IterSum**: Calculates the sum of the dataset iteratively.\n",
    "- **IterVar**: Computes the variance of the dataset in an online fashion.\n",
    "- **IterCov**: Computes the covariance matrix of two datasets incrementally.\n",
    "\n",
    "Each class is designed to update its internal state as new data becomes available, allowing for seamless integration into pipelines where data is streamed or loaded in chunks.\n",
    "\n",
    "These online computation techniques not only enable the processing of large datasets that exceed memory constraints but also offer advantages in scenarios where data arrives sequentially or in batches, such as real-time data analysis or processing data from streaming sources."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "22ad0add-6e5c-40ee-b081-809009481e88",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f1d13b25-cbc4-42dc-8560-ec4b7e50904a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class IterFunc:\n",
    "    \"\"\"Base class for iterative functions.\"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        self.n_samples = 0\n",
    "\n",
    "    def _process_batch(self, batch_data):\n",
    "        \"\"\"Process batch data and return valid data.\"\"\"\n",
    "        batch_data = np.atleast_2d(batch_data)\n",
    "        ndim = batch_data.ndim\n",
    "        axis = tuple(range(1, ndim))\n",
    "        nan_mask = np.isnan(batch_data).any(axis=axis)\n",
    "        valid_data = batch_data[~nan_mask]\n",
    "        self.n_samples += len(valid_data)\n",
    "        return valid_data\n",
    "\n",
    "    def __repr__(self):\n",
    "        return f\"{self.__class__.__name__}()\"\n",
    "\n",
    "\n",
    "class IterMean(IterFunc):\n",
    "    \"\"\"Class to calculate the mean iteratively.\"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.mean = None\n",
    "\n",
    "    def update_batch(self, batch_data):\n",
    "        \"\"\"Update the mean with batch data.\"\"\"\n",
    "        valid_data = self._process_batch(batch_data)\n",
    "        n = len(valid_data)\n",
    "        if n > 0:\n",
    "            if self.mean is None:\n",
    "                self.mean = np.mean(valid_data, axis=0)\n",
    "            else:\n",
    "                self.mean = ((self.n_samples - n) * self.mean + np.sum(valid_data, axis=0)) / self.n_samples\n",
    "        return self\n",
    "\n",
    "    def __call__(self) -> np.ndarray:\n",
    "        \"\"\"Return the mean.\"\"\"\n",
    "        if self.mean is None:\n",
    "            raise ValueError(\"No valid data to compute the mean.\")\n",
    "        return self.mean.copy()\n",
    "\n",
    "\n",
    "class IterSum(IterFunc):\n",
    "    \"\"\"Class to calculate the sum iteratively.\"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.sum = None\n",
    "\n",
    "    def update_batch(self, batch_data):\n",
    "        \"\"\"Update the sum with batch data.\"\"\"\n",
    "        valid_data = self._process_batch(batch_data)\n",
    "        if valid_data.shape[0] > 0:\n",
    "            if self.sum is None:\n",
    "                self.sum = np.sum(valid_data, axis=0)\n",
    "            else:\n",
    "                self.sum += np.sum(valid_data, axis=0)\n",
    "        return self\n",
    "\n",
    "    def __call__(self) -> np.ndarray:\n",
    "        \"\"\"Return the sum.\"\"\"\n",
    "        if self.sum is None:\n",
    "            raise ValueError(\"No valid data to compute the sum.\")\n",
    "        return self.sum.copy()\n",
    "\n",
    "\n",
    "class IterVar(IterFunc):\n",
    "    \"\"\"Class to calculate the variance iteratively.\"\"\"\n",
    "\n",
    "    def __init__(self, ddof=0):\n",
    "        super().__init__()\n",
    "        self.mean = IterMean()\n",
    "        self.var = None\n",
    "        self.ddof = ddof\n",
    "\n",
    "    def update_batch(self, v):\n",
    "        \"\"\"Update the variance with batch data.\"\"\"\n",
    "        valid_data = self._process_batch(v)\n",
    "        n = len(valid_data)\n",
    "        if n > 0:\n",
    "            if self.var is None:\n",
    "                self.var = np.var(valid_data, axis=0, ddof=0)\n",
    "                self.mean.update_batch(valid_data)\n",
    "            else:\n",
    "                previous_mean = self.mean()\n",
    "                self.mean.update_batch(valid_data)\n",
    "                updated_mean = self.mean()\n",
    "                incremental_variance = np.einsum('ji,ji->i', valid_data - previous_mean, valid_data - updated_mean)\n",
    "                self.var = ((self.n_samples - n) * self.var + incremental_variance) / self.n_samples\n",
    "        return self\n",
    "\n",
    "    def __call__(self) -> np.ndarray:\n",
    "        \"\"\"Return the variance.\"\"\"\n",
    "        if self.var is None:\n",
    "            raise ValueError(\"No valid data to compute the variance.\")\n",
    "        return self.n_samples / (self.n_samples - self.ddof) * self.var\n",
    "\n",
    "\n",
    "class IterCov(IterFunc):\n",
    "    \"\"\"Class to calculate the covariance iteratively.\"\"\"\n",
    "\n",
    "    def __init__(self, ddof=0):\n",
    "        super().__init__()\n",
    "        self.mean1 = IterMean()\n",
    "        self.mean2 = IterMean()\n",
    "        self.cov = None\n",
    "        self.ddof = ddof\n",
    "\n",
    "    def _process_batch(self, v1, v2):\n",
    "        \"\"\"Process two batches of data and return valid data.\"\"\"\n",
    "        w1, w2 = np.atleast_2d(v1), np.atleast_2d(v2)\n",
    "        if len(w1) != len(w2):\n",
    "            raise ValueError(\"v1 and v2 have different lengths!\")\n",
    "        mask = (~np.any(np.isnan(w1), axis=1)) & (~np.any(np.isnan(w2), axis=1))\n",
    "        self.n_samples += mask.sum()\n",
    "        return w1[mask], w2[mask]\n",
    "\n",
    "    def update_batch(self, v1, v2):\n",
    "        \"\"\"Update the covariance with two batches of data.\"\"\"\n",
    "        w1, w2 = self._process_batch(v1, v2)\n",
    "        n = len(w1)\n",
    "        if n > 0:\n",
    "            if self.cov is None:\n",
    "                n1, n2 = w1.shape[1], w2.shape[1]\n",
    "                self.mean1.update_batch(w1)\n",
    "                self.mean2.update_batch(w2)\n",
    "                if n == 1:\n",
    "                    self.cov = np.zeros((n1, n2))\n",
    "                else:\n",
    "                    self.cov = (w1-self.mean1()).T@((w2-self.mean2())/n)\n",
    "            else:\n",
    "                # the order of the 6 following lines is important\n",
    "                m1 = self.mean1()\n",
    "                self.mean2.update_batch(w2)\n",
    "                m2 = self.mean2()\n",
    "                self.cov += (w1-m1).T@((w2-m2)/self.mean1.n_samples)\n",
    "                self.cov *= (self.mean1.n_samples/self.mean2.n_samples)\n",
    "                self.mean1.update_batch(w1)\n",
    "\n",
    "    def __call__(self) -> np.ndarray:\n",
    "        \"\"\"Return the covariance.\"\"\"\n",
    "        if self.cov is None:\n",
    "            raise ValueError(\"No valid data to compute the covariance.\")\n",
    "        return self.n_samples/(self.n_samples - self.ddof)*self.cov"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de86d516-cc00-4c99-8ac4-b418bec6df59",
   "metadata": {},
   "source": [
    "We conduct tests to verify the correctness and functionality of the iterative computation classes: `IterSum`, `IterMean`, `IterVar`, and `IterCov`. Each test function takes input data and splits it into a specified number of batches. It then iteratively updates an instance of the corresponding class with each batch of data and verifies whether the computed statistical quantity matches the expected value. We utilize the `np.allclose` function to check for numerical closeness between the computed value and the ground truth value. Upon running each test, if the computed value matches the expected value within a reasonable tolerance, the function returns 'OK!', indicating that the respective implementation behaves as expected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c424c85f-1809-4b97-9f1f-e1ea85f80f59",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_samples = 1_000_000\n",
    "n_features = 50\n",
    "n_batches = 31\n",
    "data = np.random.randn(n_samples, n_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0d24cccc-b17f-4350-9220-b060babe38b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'OK!'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def test_IterSum(data, n_batches):\n",
    "    itersum = IterSum()\n",
    "    for batch_data in np.array_split(data, n_batches):\n",
    "        itersum.update_batch(batch_data)\n",
    "    assert np.allclose(itersum(), np.sum(data, axis=0))\n",
    "    return 'OK!'\n",
    "\n",
    "\n",
    "test_IterSum(data=data, n_batches=n_batches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2107cfd4-6d61-434b-a4b7-227980e08dcf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'OK!'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def test_IterMean(data, n_batches):\n",
    "    itermean = IterMean()\n",
    "    for batch_data in np.array_split(data, n_batches):\n",
    "        itermean.update_batch(batch_data)\n",
    "    assert np.allclose(itermean(), np.mean(data, axis=0))\n",
    "    return 'OK!'\n",
    "\n",
    "\n",
    "test_IterMean(data=data, n_batches=n_batches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2e6ae60c-2daf-4530-8573-98d17343621e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'OK!'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def test_IterVar(data, n_batches):\n",
    "    itervar = IterVar(ddof=1)\n",
    "    for batch_data in np.array_split(data, n_batches):\n",
    "        itervar.update_batch(batch_data)\n",
    "    assert np.allclose(itervar(), np.var(data, axis=0, ddof=1))\n",
    "    return 'OK!'\n",
    "\n",
    "\n",
    "test_IterVar(data=data, n_batches=n_batches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "67f6c9e0-3b84-4bf7-be6e-f0f438dc0ac0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'OK!'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def test_IterVar_IterCov(data, n_batches):\n",
    "    itervar = IterVar()\n",
    "    itercov = IterCov()\n",
    "\n",
    "    for batch_data in np.array_split(data, n_batches):\n",
    "        itervar.update_batch(batch_data)\n",
    "        itercov.update_batch(batch_data, batch_data)\n",
    "\n",
    "    cov = itercov()\n",
    "    var = itervar()\n",
    "\n",
    "    true_cov = np.cov(data.T, ddof=0)\n",
    "    true_var = np.var(data, axis=0)\n",
    "\n",
    "    assert np.allclose(cov, true_cov)\n",
    "    assert np.allclose(var, true_var)\n",
    "    assert np.allclose(var, np.diag(cov))\n",
    "    return 'OK!'\n",
    "\n",
    "\n",
    "test_IterVar_IterCov(data=data, n_batches=n_batches)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
